<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="icon" href="logo/2890566_ai_artificial intelligence_automaton_brain_electronics_icon.png">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>
    <nav>
        <input type="checkbox" id="check">
        <label for="check" class="checkbtn">
          <i class="fas fa-bars"></i>
        </label>
        <label class="logo">YORA TECH</label>
        <ul>
          <li><a href="index.html" class="ar">Home</a></li>
          <li><a href="reviews.html" class="ar">Team</a></li>
          <li><a href="contact.html" class="ar" target="_blank">Contact</a></li>
        </ul>
      </nav>
    <br>
    <h1 class="raytech">Machine Learning</h1>
    <br>
    <img src="img/machine-learning.jpg" class="banner1">
    <br>
    <div class="die">
        <h2 class="st1 text" id="ar">MACHINE LEARNING :</h2>
        <p class="text">Machine learning (ML) is the study of computer algorithms that can learn and develop on their own with experience and data. It is considered to be a component of artificial intelligence. Machine learning algorithms create a model based on training data to make predictions or judgments without having to be explicitly programmed to do so. Machine learning algorithms are utilized in a wide range of applications, including medicine, email filtering, speech recognition, and computer vision, where developing traditional algorithms to do the required tasks is difficult or impossible.
        </p>
        <br>
        <h2 class="st1 text" id="ari">OVERVIEW :</h2>
        <p class="text">Learning algorithms are based on the assumption that methods, algorithms, and conclusions that have worked in the past would likely continue to work in the future. These inferences can be clear, such as "because the sun has been rising every morning for the last 10,000 days, it will most likely rise again tomorrow morning." "X percent of families include geographically different species with color variants, thus there's a Y percent possibility that undiscovered black swans exist," for example.
            <br>
            <br>
            Without being expressly designed, machine learning programs may complete tasks. It entails computers learning from data in order to do specific jobs. It is possible to write algorithms that inform the machine how to perform all steps required to solve the problem at hand for basic jobs entrusted to computers; no learning is required on the computer's behalf. It can be difficult for a human to manually build the algorithms required for increasingly complicated tasks. In practice, assisting the computer in developing its own algorithm rather than having human programmers explain each required step can prove to be more productive.
            <br>
            <br>
            Machine learning is a discipline that uses a variety of ways to train computers how to complete tasks for which no entirely suitable solution exists. When there are a large number of possible replies, one strategy is to classify some of the correct answers as valid. The computer can then utilize this as training data to refine the algorithm(s) it uses to determine right answers. The MNIST dataset of handwritten digits, for example, has frequently been used to train a system for the task of digital character recognition.
        </p>
        <br>

        <h2 class="st1 text" id="art">MACHINE LEARNING CATEGORIES :</h2>
        <h3 class="text">Supervised learning</h3>
        <br>
        <p class="text">Supervised learning algorithms create a mathematical model of a set of data that includes both the inputs and outputs.  The data is referred to as training data, and it is made up of a series of training examples. Each training example has one or more inputs and a supervisory signal as an output. Each training sample is represented by an array or vector, sometimes referred to as a feature vector, in the mathematical model, whereas the training data is represented by a matrix. Supervised learning techniques develop a function that may be used to predict the output associated with fresh inputs through iterative optimization of an objective function.</p>
        <br>
        <h3 class="text">Unsupervised learning</h3>
        <br>
        <p class="text">Unsupervised learning methods take a collection of data with only inputs and detect structure in it, such as data point grouping or clustering. As a result, the algorithms learn from unlabeled, unclassified, and uncategorized test data. Unsupervised learning algorithms discover commonalities in the data and react depending on the existence or lack of such commonalities in each new piece of data, rather than responding to feedback. The field of density estimation in statistics, such as calculating the probability density function, is a key application of unsupervised learning.  Unsupervised learning, on the other hand, comprises various domains that need summarizing and explaining data aspects.</p>
        <br>
        <h3 class="text">Semi-supervised learning</h3>
        <br>
        <p class="text">Unsupervised learning (without any labeled training data) and supervised learning (with labeled training data) are the two types of learning (with completely labeled training data). Although some of the training examples lack training labels, several machine-learning researchers have discovered that unlabeled data, when combined with a modest amount of labeled data, can enhance learning accuracy significantly.
                        <br>
                        <br>
                        The training labels in weakly supervised learning are noisy, limited, or imprecise, yet they are generally cheaper to obtain, resulting in larger effective training sets.</p>
        <br>
        <h3 class="text">Self learning</h3>
        <br>
        <p class="text">In 1982, self-learning as a machine learning paradigm was proposed, coupled with the crossbar adaptive array, a neural network capable of self-learning (CAA). It is a type of learning in where there are no external rewards or teacher recommendations. The CAA self-learning algorithm computes both actions and emotions (feelings) in consequence scenarios in a crossbar fashion. The combination of cognition and emotion drives the system.</p>
        <br>
        <h3 class="text">Feature learning</h3>
        <br>
        <p class="text">Several learning algorithms are aimed at finding better representations of the training inputs. Principal component and cluster analysis are two well-known examples. Feature learning algorithms, also known as representation learning algorithms, try to conserve the information in their input while also transforming it in a useful fashion, usually as a pre-processing step before conducting classification or predictions. This technique allows the inputs from an unknown data-generating distribution to be reconstructed, but it is not always true to configurations that are implausible for that distribution. This eliminates the need for manual feature engineering by allowing a machine to learn and apply features to complete a task.</p>
        <br>
        <h3 class="text">Genetic algorithms</h3>
        <br>
        <p class="text">A genetic algorithm (GA) is a search algorithm and heuristic tool that mimics the process of natural selection by generating new genotypes using methods such as mutation and crossover in the hopes of discovering appropriate solutions to a given problem. In the 1980s and 1990s, genetic algorithms were applied in machine learning. Machine learning approaches, on the other hand, have been utilized to enhance the performance of genetic and evolutionary algorithms.</p>
        <br>
        <h3 class="text">Anomaly detection</h3>
        <br>
        <p class="text">Anomaly detection, also known as outlier detection, is the process of identifying unusual things, occurrences, or observations that raise suspicions by varying considerably from the rest of the data. Typically, the abnormal elements indicate a problem such as bank fraud, a structural flaw, medical issues, or textual faults. Outliers, novelties, noise, deviations, and exceptions are all terms used to describe anomalies.
                        <br>
                        <br>
                        In the context of abuse and network intrusion detection, the intriguing objects are frequently unexpected spurts of inactivity, rather than infrequent items. Many outlier detection approaches would fail on such data unless it has been aggregated adequately, as this pattern does not comply to the standard statistical definition of an outlier as an uncommon object.</p>
        <br>
        <h3 class="text">Sparse dictionary learning</h3>
        <br>
        <p class="text">Sparse dictionary learning is a feature learning method in which a training example is represented as a linear combination of basis functions in a sparse matrix. The method is NP-hard and approximate to solve. The K-SVD technique is a prominent heuristic for sparse dictionary learning. Sparse dictionary learning has been used in a variety of settings. The goal of classification is to figure out which class a previously unknown training example belongs to. A new training example is connected with the class that is best sparsely represented by the matching dictionary in a dictionary where each class has already been created. Image de-noising has also used sparse dictionary learning. The main premise is that a simple image patch can fix a lot of problems.</p>
        <br>
        <h3 class="text">Feature learning</h3>
        <br>
        <p class="text">Several learning algorithms are aimed at discovering more accurate representations of the training inputs. Principal component analysis and cluster analysis are two well-known examples. Feature learning algorithms, also known as representation learning algorithms, try to conserve the information in their input while also transforming it in a useful fashion, usually as a pre-processing step before doing classification or prediction. This technique allows the inputs from an unknown data-generating distribution to be reconstructed, but it is not always true to configurations that are improbable under that distribution. This eliminates the need for manual feature engineering and lets a machine to learn and use features to fulfill a given activity.</p>
        <br>
        <h3 class="text">Reinforcement learning</h3>
        <br>
        <p class="text">Reinforcement learning is a branch of machine learning that studies how software agents should behave in a given environment in order to maximize some metric of cumulative reward. Game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms are among the numerous disciplines that study the field due to its generality. The environment is generally represented as a Markov decision process in machine learning (MDP). Dynamic programming techniques are used in many reinforcement learning systems. When exact mathematical models of the MDP are infeasible, reinforcement learning procedures are applied. Reinforcement learning algorithms are employed in autonomous vehicles and in teaching humans how to play a game.</p>
    </div>
    <footer>
        <div class="footer-bottom">
            <p>copyright &copy;2020 YORA TECH. create by <span>rayen lakhal &amp; youssef abida</span></p>
        </div>
    </footer>
</body>
</html>
